{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[NLP복습] 단어의 분산 표현.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMZg8EkCX5d0aKoleDrZVYd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zzhenxi/TIL/blob/main/%5BNLP%EB%B3%B5%EC%8A%B5%5D_%EB%8B%A8%EC%96%B4%EC%9D%98_%EB%B6%84%EC%82%B0_%ED%91%9C%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gensim 패키지를 사용하여 word2vec 인베딩 확인해보기"
      ],
      "metadata": {
        "id": "aN2FYO_nfvuc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg2YGu8UfauZ",
        "outputId": "5d1d6694-fe33-469a-8b91-404aacb81e71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.1.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "gensim.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RZwpJKjsfpmK",
        "outputId": "34085331-9621-44a0-e78a-535c24d77c52"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4.1.2'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "wv = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL03pKvvfskv",
        "outputId": "f1384f44-c507-4356-e2fd-679fe29e5aab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, word in enumerate(wv.index_to_key):\n",
        "    if idx == 10:\n",
        "        break\n",
        "\n",
        "    print(f\"word #{idx}/{len(wv.index_to_key)} is '{word}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKjWQ6OMf7pa",
        "outputId": "6f11b8e3-2c4a-4b77-dbfc-8b13cf43f651"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word #0/3000000 is '</s>'\n",
            "word #1/3000000 is 'in'\n",
            "word #2/3000000 is 'for'\n",
            "word #3/3000000 is 'that'\n",
            "word #4/3000000 is 'is'\n",
            "word #5/3000000 is 'on'\n",
            "word #6/3000000 is '##'\n",
            "word #7/3000000 is 'The'\n",
            "word #8/3000000 is 'with'\n",
            "word #9/3000000 is 'said'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec_king = wv['king']\n",
        "\n",
        "print(f\"Embedding dimesion is : {vec_king.shape}\\n\")\n",
        "print(f\"Embedding vector of 'king' is \\n\\n {vec_king}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4vzmzW3gBGe",
        "outputId": "398ad134-9e22-47b2-fe32-3d1723ad4aa8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding dimesion is : (300,)\n",
            "\n",
            "Embedding vector of 'king' is \n",
            "\n",
            " [ 1.25976562e-01  2.97851562e-02  8.60595703e-03  1.39648438e-01\n",
            " -2.56347656e-02 -3.61328125e-02  1.11816406e-01 -1.98242188e-01\n",
            "  5.12695312e-02  3.63281250e-01 -2.42187500e-01 -3.02734375e-01\n",
            " -1.77734375e-01 -2.49023438e-02 -1.67968750e-01 -1.69921875e-01\n",
            "  3.46679688e-02  5.21850586e-03  4.63867188e-02  1.28906250e-01\n",
            "  1.36718750e-01  1.12792969e-01  5.95703125e-02  1.36718750e-01\n",
            "  1.01074219e-01 -1.76757812e-01 -2.51953125e-01  5.98144531e-02\n",
            "  3.41796875e-01 -3.11279297e-02  1.04492188e-01  6.17675781e-02\n",
            "  1.24511719e-01  4.00390625e-01 -3.22265625e-01  8.39843750e-02\n",
            "  3.90625000e-02  5.85937500e-03  7.03125000e-02  1.72851562e-01\n",
            "  1.38671875e-01 -2.31445312e-01  2.83203125e-01  1.42578125e-01\n",
            "  3.41796875e-01 -2.39257812e-02 -1.09863281e-01  3.32031250e-02\n",
            " -5.46875000e-02  1.53198242e-02 -1.62109375e-01  1.58203125e-01\n",
            " -2.59765625e-01  2.01416016e-02 -1.63085938e-01  1.35803223e-03\n",
            " -1.44531250e-01 -5.68847656e-02  4.29687500e-02 -2.46582031e-02\n",
            "  1.85546875e-01  4.47265625e-01  9.58251953e-03  1.31835938e-01\n",
            "  9.86328125e-02 -1.85546875e-01 -1.00097656e-01 -1.33789062e-01\n",
            " -1.25000000e-01  2.83203125e-01  1.23046875e-01  5.32226562e-02\n",
            " -1.77734375e-01  8.59375000e-02 -2.18505859e-02  2.05078125e-02\n",
            " -1.39648438e-01  2.51464844e-02  1.38671875e-01 -1.05468750e-01\n",
            "  1.38671875e-01  8.88671875e-02 -7.51953125e-02 -2.13623047e-02\n",
            "  1.72851562e-01  4.63867188e-02 -2.65625000e-01  8.91113281e-03\n",
            "  1.49414062e-01  3.78417969e-02  2.38281250e-01 -1.24511719e-01\n",
            " -2.17773438e-01 -1.81640625e-01  2.97851562e-02  5.71289062e-02\n",
            " -2.89306641e-02  1.24511719e-02  9.66796875e-02 -2.31445312e-01\n",
            "  5.81054688e-02  6.68945312e-02  7.08007812e-02 -3.08593750e-01\n",
            " -2.14843750e-01  1.45507812e-01 -4.27734375e-01 -9.39941406e-03\n",
            "  1.54296875e-01 -7.66601562e-02  2.89062500e-01  2.77343750e-01\n",
            " -4.86373901e-04 -1.36718750e-01  3.24218750e-01 -2.46093750e-01\n",
            " -3.03649902e-03 -2.11914062e-01  1.25000000e-01  2.69531250e-01\n",
            "  2.04101562e-01  8.25195312e-02 -2.01171875e-01 -1.60156250e-01\n",
            " -3.78417969e-02 -1.20117188e-01  1.15234375e-01 -4.10156250e-02\n",
            " -3.95507812e-02 -8.98437500e-02  6.34765625e-03  2.03125000e-01\n",
            "  1.86523438e-01  2.73437500e-01  6.29882812e-02  1.41601562e-01\n",
            " -9.81445312e-02  1.38671875e-01  1.82617188e-01  1.73828125e-01\n",
            "  1.73828125e-01 -2.37304688e-01  1.78710938e-01  6.34765625e-02\n",
            "  2.36328125e-01 -2.08984375e-01  8.74023438e-02 -1.66015625e-01\n",
            " -7.91015625e-02  2.43164062e-01 -8.88671875e-02  1.26953125e-01\n",
            " -2.16796875e-01 -1.73828125e-01 -3.59375000e-01 -8.25195312e-02\n",
            " -6.49414062e-02  5.07812500e-02  1.35742188e-01 -7.47070312e-02\n",
            " -1.64062500e-01  1.15356445e-02  4.45312500e-01 -2.15820312e-01\n",
            " -1.11328125e-01 -1.92382812e-01  1.70898438e-01 -1.25000000e-01\n",
            "  2.65502930e-03  1.92382812e-01 -1.74804688e-01  1.39648438e-01\n",
            "  2.92968750e-01  1.13281250e-01  5.95703125e-02 -6.39648438e-02\n",
            "  9.96093750e-02 -2.72216797e-02  1.96533203e-02  4.27246094e-02\n",
            " -2.46093750e-01  6.39648438e-02 -2.25585938e-01 -1.68945312e-01\n",
            "  2.89916992e-03  8.20312500e-02  3.41796875e-01  4.32128906e-02\n",
            "  1.32812500e-01  1.42578125e-01  7.61718750e-02  5.98144531e-02\n",
            " -1.19140625e-01  2.74658203e-03 -6.29882812e-02 -2.72216797e-02\n",
            " -4.82177734e-03 -8.20312500e-02 -2.49023438e-02 -4.00390625e-01\n",
            " -1.06933594e-01  4.24804688e-02  7.76367188e-02 -1.16699219e-01\n",
            "  7.37304688e-02 -9.22851562e-02  1.07910156e-01  1.58203125e-01\n",
            "  4.24804688e-02  1.26953125e-01  3.61328125e-02  2.67578125e-01\n",
            " -1.01074219e-01 -3.02734375e-01 -5.76171875e-02  5.05371094e-02\n",
            "  5.26428223e-04 -2.07031250e-01 -1.38671875e-01 -8.97216797e-03\n",
            " -2.78320312e-02 -1.41601562e-01  2.07031250e-01 -1.58203125e-01\n",
            "  1.27929688e-01  1.49414062e-01 -2.24609375e-02 -8.44726562e-02\n",
            "  1.22558594e-01  2.15820312e-01 -2.13867188e-01 -3.12500000e-01\n",
            " -3.73046875e-01  4.08935547e-03  1.07421875e-01  1.06933594e-01\n",
            "  7.32421875e-02  8.97216797e-03 -3.88183594e-02 -1.29882812e-01\n",
            "  1.49414062e-01 -2.14843750e-01 -1.83868408e-03  9.91210938e-02\n",
            "  1.57226562e-01 -1.14257812e-01 -2.05078125e-01  9.91210938e-02\n",
            "  3.69140625e-01 -1.97265625e-01  3.54003906e-02  1.09375000e-01\n",
            "  1.31835938e-01  1.66992188e-01  2.35351562e-01  1.04980469e-01\n",
            " -4.96093750e-01 -1.64062500e-01 -1.56250000e-01 -5.22460938e-02\n",
            "  1.03027344e-01  2.43164062e-01 -1.88476562e-01  5.07812500e-02\n",
            " -9.37500000e-02 -6.68945312e-02  2.27050781e-02  7.61718750e-02\n",
            "  2.89062500e-01  3.10546875e-01 -5.37109375e-02  2.28515625e-01\n",
            "  2.51464844e-02  6.78710938e-02 -1.21093750e-01 -2.15820312e-01\n",
            " -2.73437500e-01 -3.07617188e-02 -3.37890625e-01  1.53320312e-01\n",
            "  2.33398438e-01 -2.08007812e-01  3.73046875e-01  8.20312500e-02\n",
            "  2.51953125e-01 -7.61718750e-02 -4.66308594e-02 -2.23388672e-02\n",
            "  2.99072266e-02 -5.93261719e-02 -4.66918945e-03 -2.44140625e-01\n",
            " -2.09960938e-01 -2.87109375e-01 -4.54101562e-02 -1.77734375e-01\n",
            " -2.79296875e-01 -8.59375000e-02  9.13085938e-02  2.51953125e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unk = 'cameroon'\n",
        "\n",
        "try:\n",
        "    vec_unk = wv[unk]\n",
        "except KeyError:\n",
        "    print(f\"The word #{unk} does not appear in this model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzYMjIa1gNp2",
        "outputId": "de6b3b9f-f3a4-4e36-ea4f-63e319d67d8b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The word #cameroon does not appear in this model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서 알 수 있는 word2vec의 단점 : 모르는 단어에서는 Keyerorr가 발생한다."
      ],
      "metadata": {
        "id": "Xo4I0H39gP2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = [\n",
        "    ('car', 'minivan'),   \n",
        "    ('car', 'bicycle'),  \n",
        "    ('car', 'airplane'),\n",
        "    ('car', 'cereal'),    \n",
        "    ('car', 'democracy')\n",
        "]\n",
        "\n",
        "for w1, w2 in pairs:\n",
        "    print(f'{w1} ======= {w2}\\t  {wv.similarity(w1, w2):.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzJf0eV9gZOo",
        "outputId": "11e884af-41a1-4835-9c84-0be48355e7fd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "car ======= minivan\t  0.69\n",
            "car ======= bicycle\t  0.54\n",
            "car ======= airplane\t  0.42\n",
            "car ======= cereal\t  0.14\n",
            "car ======= democracy\t  0.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# korea와 japan의 유사도는?\n",
        "wv.similarity('korea', 'japan')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wWNuvF0h4Vg",
        "outputId": "fff857ad-e2c2-4551-8558-d46ddfe1d1cf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5766093"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (word, similarity) in enumerate(wv.most_similar(positive=['car', 'minivan'], topn=5)):\n",
        "    print(f\"Top {i+1} : {word}, {similarity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdjrofyNh06k",
        "outputId": "c7b2f4ec-db3f-4e0e-cee9-7d9e85c15ed2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 1 : SUV, 0.8532192707061768\n",
            "Top 2 : vehicle, 0.8175783753395081\n",
            "Top 3 : pickup_truck, 0.7763688564300537\n",
            "Top 4 : Jeep, 0.7567334175109863\n",
            "Top 5 : Ford_Explorer, 0.7565720081329346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wv.most_similar(positive=['canada', 'usa'], topn=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XMlZCZQiIPM",
        "outputId": "12962b78-16e8-47a3-a990-9c53cf99d5d7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('australia', 0.7461850643157959),\n",
              " ('uk', 0.7346195578575134),\n",
              " ('india', 0.7198905944824219),\n",
              " ('canadian', 0.713864803314209),\n",
              " ('mexico', 0.6899615526199341)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wv.doesnt_match(['fire', 'water', 'land', 'sea', 'air', 'car']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKn5JO51iSZg",
        "outputId": "df41842c-995e-4891-85b5-f7cb4ef9dd9e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "car\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fast text (word2vec방식+철자 단위 임베딩) : unknown단어에 대해서도 처리 가능!   \n",
        "character n-gram    \n",
        "접두사 접미사를 인식할 수 있도록 단어 앞뒤로 <>를 붙여줌    \n",
        "접두사/접미사란? https://post.naver.com/viewer/postView.nhn?volumeNo=23305226&memberNo=46639488   \n"
      ],
      "metadata": {
        "id": "9t3vtusbj5Qb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3-6 gram을 구해준다.    \n",
        "\n",
        "예로 eating에 대한 5-gram을 구한다면   \n",
        "<eat, eatin, ating, ting>   \n",
        "eating에 대한 6-gram을 구한다면   \n",
        "<eatin, eating, ating>   \n",
        "\n",
        "이렇게 구해진 n-gram들에 대해 모두 임베딩 벡터를 구하게 된다.   \n",
        "eating이라는 단어가 말뭉치 내에 있다면?   \n",
        "-> skip-gram으로부터 학습한 임베딩 벡터에 위에서 얻은 character level의 n-gram 벡터를 더해줌    \n",
        "eating이라는 단어가 말뭉치 내에 없다면?    \n",
        "-> 더할게 없으므로 그냥 character level의 n-gram 벡터만으로 구성\n"
      ],
      "metadata": {
        "id": "Vvqqauz7l2Q4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "gensim을 이용한 fasttext 실습"
      ],
      "metadata": {
        "id": "ZEs30_Mcr4hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint as print\n",
        "from gensim.models.fasttext import FastText\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "# Set file names for train and test data\n",
        "corpus_file = datapath('lee_background.cor')\n",
        "\n",
        "model = FastText(vector_size=100)\n",
        "\n",
        "# build the vocabulary\n",
        "model.build_vocab(corpus_file=corpus_file)\n",
        "\n",
        "# train the model\n",
        "model.train(\n",
        "    corpus_file=corpus_file, epochs=model.epochs,\n",
        "    total_examples=model.corpus_count, total_words=model.corpus_total_words,\n",
        ")\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbBoW8JJkyqz",
        "outputId": "ddaf5bf8-2656-4d4b-f5ac-0eaff24f1eed"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<gensim.models.fasttext.FastText object at 0x7f59c239bc10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft = model.wv\n",
        "print(ft)\n",
        "\n",
        "#\n",
        "# FastText models support vector lookups for out-of-vocabulary words by summing up character ngrams belonging to the word.\n",
        "#\n",
        "print(f\"night => {'night' in ft.key_to_index}\")\n",
        "print(f\"nights => {'nights' in ft.key_to_index}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Hwfk-JCkU6E",
        "outputId": "e2ede901-0cb2-4bb8-adf9-94302320c1e5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<gensim.models.fasttext.FastTextKeyedVectors object at 0x7f59b9a636d0>\n",
            "'night => True'\n",
            "'nights => False'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ft['night'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I91jm8QLjrFk",
        "outputId": "8a90073e-2606-41c6-9e40-686623fb0dfc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array([-0.1652651 ,  0.14666401, -0.24353024, -0.07762306,  0.05742531,\n",
            "        0.3570904 ,  0.35509378,  0.52626187,  0.16666628, -0.23894814,\n",
            "        0.0224785 , -0.15402146, -0.24611385,  0.573883  , -0.3745006 ,\n",
            "       -0.54706603,  0.12348378, -0.23135562, -0.46608412, -0.52813596,\n",
            "       -0.48962465, -0.02548056, -0.5087586 , -0.13894382, -0.16880122,\n",
            "       -0.26709124, -0.6249031 , -0.08531766, -0.26740587,  0.24598727,\n",
            "       -0.30003005,  0.3142181 ,  0.8141345 , -0.24763955,  0.20267023,\n",
            "        0.29988053,  0.3898106 , -0.04237102, -0.3653215 , -0.2936849 ,\n",
            "        0.51645744, -0.45147625,  0.06804629, -0.37505332, -0.56251216,\n",
            "       -0.3592315 , -0.0741737 ,  0.1422336 ,  0.3076743 , -0.03643672,\n",
            "        0.36363703, -0.4669334 ,  0.28283617, -0.44197252, -0.2031839 ,\n",
            "       -0.1969611 , -0.17908098, -0.13947977,  0.01480718, -0.32706085,\n",
            "       -0.35901847, -0.46089664, -0.22634028,  0.3639972 , -0.0529095 ,\n",
            "        0.6853143 ,  0.05301911, -0.01250035,  0.391493  ,  0.3173556 ,\n",
            "       -0.18648796,  0.4519545 ,  0.55753785, -0.66898894,  0.32443634,\n",
            "       -0.09822956,  0.27801937, -0.10659372,  0.11129247,  0.3946666 ,\n",
            "        0.13698101, -0.47564933, -0.7569055 , -0.18127051, -0.1076705 ,\n",
            "       -0.78041834,  0.45279506,  0.2270489 , -0.06810017, -0.34272516,\n",
            "       -0.05758766,  0.37506852, -0.14290805,  0.03786873, -0.25453416,\n",
            "        0.5814736 , -0.20287211, -0.25464252, -0.04737847, -0.25060135],\n",
            "      dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ft['nights'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xibhERXbsGd_",
        "outputId": "e26680bd-9171-41c9-bbe8-578e794e6486"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array([-0.14422518,  0.12827557, -0.211607  , -0.06723659,  0.04860283,\n",
            "        0.30889356,  0.309741  ,  0.45898873,  0.1452508 , -0.20921576,\n",
            "        0.02127368, -0.13229148, -0.21487856,  0.4964029 , -0.32665002,\n",
            "       -0.47577885,  0.10653514, -0.20045201, -0.4034646 , -0.45945776,\n",
            "       -0.42240447, -0.02321842, -0.44181526, -0.12212082, -0.14528081,\n",
            "       -0.23054335, -0.54140294, -0.07188367, -0.23198271,  0.21519102,\n",
            "       -0.25862688,  0.27239764,  0.7052956 , -0.21466248,  0.17613226,\n",
            "        0.25988388,  0.33990917, -0.03676734, -0.31746837, -0.25561023,\n",
            "        0.44763246, -0.39116174,  0.05855536, -0.32516485, -0.4892997 ,\n",
            "       -0.3107261 , -0.06150847,  0.12413989,  0.26857477, -0.03054684,\n",
            "        0.31733486, -0.4057174 ,  0.2462727 , -0.38374415, -0.17599133,\n",
            "       -0.16978486, -0.15743463, -0.11934985,  0.01417491, -0.28133556,\n",
            "       -0.31073081, -0.40056434, -0.19618067,  0.3155762 , -0.04534699,\n",
            "        0.59612286,  0.04613607, -0.01348162,  0.3396752 ,  0.27672315,\n",
            "       -0.16241258,  0.39053696,  0.485278  , -0.58078134,  0.28320467,\n",
            "       -0.08427062,  0.24080443, -0.09338449,  0.09641629,  0.34275648,\n",
            "        0.11942453, -0.41342103, -0.6566213 , -0.15845813, -0.09249798,\n",
            "       -0.67885274,  0.3931507 ,  0.1973587 , -0.05706302, -0.29824588,\n",
            "       -0.04994369,  0.3244873 , -0.12460632,  0.03353191, -0.22150938,\n",
            "        0.5050845 , -0.17752393, -0.2175017 , -0.04080679, -0.21845528],\n",
            "      dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ft.similarity(\"night\", \"nights\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_Q8ly9nsL36",
        "outputId": "3fc94173-e953-4fda-d82a-cac5b1398d7d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.99999195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ft.most_similar(\"nights\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xIGZf0GsN2f",
        "outputId": "7a978850-9e06-49b5-8c14-5259e3bfdfd2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('night', 0.999991774559021),\n",
            " ('rights', 0.9999878406524658),\n",
            " ('flights', 0.9999876618385315),\n",
            " ('overnight', 0.999987006187439),\n",
            " ('fighting', 0.9999856352806091),\n",
            " ('entered', 0.9999853372573853),\n",
            " ('fighters', 0.9999851584434509),\n",
            " ('fight', 0.9999849796295166),\n",
            " ('fighter', 0.999984860420227),\n",
            " ('treated', 0.9999845623970032)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "비슷하게 생긴 (비슷한 chracter n-gram이 포함된) 단어가 많이 속해있음"
      ],
      "metadata": {
        "id": "qo0AyePtsRJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ft.doesnt_match(\"night noon fight morning\".split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxXKaEdfsO5n",
        "outputId": "620eb6b3-3bec-45c5-e307-35fa3b8f6826"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'noon'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fasttext 임베딩 벡터는 단어의 의미보다는 단어의 모양에 더 신경쓰는 것 같기도..."
      ],
      "metadata": {
        "id": "ExfqWF6dsrVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ft.doesnt_match(\"bye hello hi mellon\".split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4QkYh-SshJt",
        "outputId": "20cd68bb-28a6-4b33-fcff-40cc185c7cbc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'bye'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 아까의 word2vec다시 한번 보자\n",
        "print(wv.doesnt_match(['bye', 'hello', 'hi', 'mellon']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY9FwFrntVlQ",
        "outputId": "e2d93574-7be0-4362-8c4f-0ce8c5345190"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'mellon'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그냥 word2vec은 잘 구별하는 것을 알 수 있다. (의미 중심으로 임베딩이 되어서 그런 듯)"
      ],
      "metadata": {
        "id": "2Tp8ax-_tnUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.datasets import imdb"
      ],
      "metadata": {
        "id": "Y60LVcbHulUX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42) # 항상 같은 결과를 도출하기 위해 전역 random seed 설정 "
      ],
      "metadata": {
        "id": "yjdyOG-HtmrR"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=20000)\n",
        "# imdb의 return은 (X_train, y_train), (X_test, y_test)형식이라고 한다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8tQRVTjtlei",
        "outputId": "55301fb6-1fd5-4979-b856-84a28b0e1d73"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train set shape : {X_train.shape}\")\n",
        "print(f\"Test set shape : {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWkNWK05wixT",
        "outputId": "0323b96a-9968-47ab-fc9b-1d7fc549b95f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Train set shape : (25000,)'\n",
            "'Test set shape : (25000,)'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0] # 이게 뭘 한거지............! 인덱스라고 한다. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yed1zbqWxPdk",
        "outputId": "8a47614f-c0ca-4507-c69c-ae7b85440353"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 19193,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 10311,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 12118,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    \"\"\"\n",
        "    word_index를 받아 text를 sequence 형태로 반환하는 함수입니다.\n",
        "    \"\"\"\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-LVW9jsxP5P",
        "outputId": "f19ce088-9013-4295-b6f8-45442a11a617"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode_review(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "cgpkgeBvxdxR",
        "outputId": "01435b17-969d-4f90-8a86-6e420eeb9073"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [decode_review(idx) for idx in X_train]\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)"
      ],
      "metadata": {
        "id": "0dZIYlegzLzJ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCyvJnkq0Ydx",
        "outputId": "f0c6f254-d330-4299-9ca8-57ea9a96a021"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_encoded = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "#\n",
        "max_len = max(len(sent) for sent in X_encoded)\n",
        "print(max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3HDMbAr0aJd",
        "outputId": "a65ff14d-507d-4e15-8312-f88d1af71ee8"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Mean length of train set: {np.mean([len(sent) for sent in X_train], dtype=int)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbDZSjYI0o-1",
        "outputId": "4fb154c5-834e-4910-c27f-95d8589089fc"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Mean length of train set: 238'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=pad_sequences(X_encoded, maxlen=400, padding='post') # post는 뒤에 0을 붙여준다는 뜻\n",
        "y_train=np.array(y_train)"
      ],
      "metadata": {
        "id": "kTcPApMc0tpu"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "\n",
        "print(np.shape(embedding_matrix)) # 가중치 행렬 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk2_Bz6k4Ih9",
        "outputId": "a021a445-74c1-47da-fec2-31374c54cbd9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19999, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vector(word):\n",
        "    \"\"\"\n",
        "    해당 word가 word2vec에 있는 단어일 경우 임베딩 벡터를 반환\n",
        "    \"\"\"\n",
        "    if word in wv:\n",
        "        return wv[word]\n",
        "    else:\n",
        "        return None\n",
        " \n",
        "for word, i in tokenizer.word_index.items():\n",
        "    temp = get_vector(word)\n",
        "    if temp is not None:\n",
        "        embedding_matrix[i] = temp"
      ],
      "metadata": {
        "id": "UF2g8c6-4Srv"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten"
      ],
      "metadata": {
        "id": "lCmL4YXK4UMv"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_len, trainable=False))\n",
        "model.add(GlobalAveragePooling1D()) # 입력되는 단어 벡터의 평균을 구하는 함수입니다.\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "OcxMXY1B6p11"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "임베딩 레이어는 어떻게 작동하는가?   \n",
        "https://androidkt.com/how-embedding-layer-work-in-keras/"
      ],
      "metadata": {
        "id": "i4FT1iKf_Ql1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgqaVRvo_z1o",
        "outputId": "c88eb74a-38fc-4694-e9fd-d132c306f31f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   30,    12,    20,    14,    42,   528,   970,  1620,  1383,\n",
              "          64,   457,  4451,    65,  3932,     1,   172,    35,   255,\n",
              "           3,    23,    99,    42,   837,   111,    49,   669,     2,\n",
              "           7,    34,   479,   283,     3,   149,     1,   171,   111,\n",
              "         166,     2,   335,   384,    38,     1,   171,  4519,  1107,\n",
              "          15,   545,    37,    11,   446,     1,   191,    49,    14,\n",
              "           4,   146,  2018,    17,    12,    20,     1,  1908,  4590,\n",
              "         468,     1,    20,    70,    86,    10,    14,    42,   528,\n",
              "          37,    75,    13,    11,  1246,     1,    20,    15,   514,\n",
              "          15,    10,    14,   624,    16, 18512,     3,    61,   385,\n",
              "          10,     6,   315,     6,   105,     3,     1,  2220,  5231,\n",
              "          14,   479,    65,  3767,    32,     1,   129,    10,    14,\n",
              "          37,   616,     3,    23,   123,    50,    35,   134,    46,\n",
              "          23,  1410,    32,     4,    20,    10,   214,    26,    76,\n",
              "          51,     3,    12,   406,    14,    81, 10309,     6,     1,\n",
              "         106,   116,  5926,    13,   255,     1,     2,     5,  3736,\n",
              "           3,   722,    35,    70,    42,   528,   475,    24,   398,\n",
              "         316,    45,     5,     1, 11928,  1027,    11,   103,    87,\n",
              "           1,   380,    13,   296,    97,    31,  2066,    55,    24,\n",
              "         140,     4,   193,  7478,    16,     1,   225,    20,    19,\n",
              "         133,   475,    24,   479,     3,   143,    28,  5516,    16,\n",
              "          50,    35,    26,   223,    91,    23,   103,     1,   225,\n",
              "          64,    14,    37,  1333,    87,    10,    14,   282,     3,\n",
              "          14,  4452,   112,   102,    31,    13,    14,  5342,    17,\n",
              "         177,    31,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "oTQXErYf6sO9",
        "outputId": "48e0759d-08a1-4c36-abbe-27b3ceb368e2"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-9322ff95e308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 2494), found shape=(None, 400)\n"
          ]
        }
      ]
    }
  ]
}