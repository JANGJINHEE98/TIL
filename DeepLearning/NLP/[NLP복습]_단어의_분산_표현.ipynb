{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[NLP복습] 단어의 분산 표현.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYiumq6eN/FClaIL/CKYfk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zzhenxi/TIL/blob/main/%5BNLP%EB%B3%B5%EC%8A%B5%5D_%EB%8B%A8%EC%96%B4%EC%9D%98_%EB%B6%84%EC%82%B0_%ED%91%9C%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gensim 패키지를 사용하여 word2vec 인베딩 확인해보기"
      ],
      "metadata": {
        "id": "aN2FYO_nfvuc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg2YGu8UfauZ",
        "outputId": "37fd7d76-67bd-4d21-9565-ef3d89197440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.1.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 8.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "gensim.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RZwpJKjsfpmK",
        "outputId": "62fbecd4-4563-4259-aeae-18c4d916e458"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4.1.2'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "wv = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL03pKvvfskv",
        "outputId": "62248bac-ed25-4551-8410-a1e1ae1f1a9d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, word in enumerate(wv.index_to_key):\n",
        "    if idx == 10:\n",
        "        break\n",
        "\n",
        "    print(f\"word #{idx}/{len(wv.index_to_key)} is '{word}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKjWQ6OMf7pa",
        "outputId": "096d7cc5-2899-42da-8fcd-ad39d274aa4a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word #0/3000000 is '</s>'\n",
            "word #1/3000000 is 'in'\n",
            "word #2/3000000 is 'for'\n",
            "word #3/3000000 is 'that'\n",
            "word #4/3000000 is 'is'\n",
            "word #5/3000000 is 'on'\n",
            "word #6/3000000 is '##'\n",
            "word #7/3000000 is 'The'\n",
            "word #8/3000000 is 'with'\n",
            "word #9/3000000 is 'said'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec_king = wv['king']\n",
        "\n",
        "print(f\"Embedding dimesion is : {vec_king.shape}\\n\")\n",
        "print(f\"Embedding vector of 'king' is \\n\\n {vec_king}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4vzmzW3gBGe",
        "outputId": "fda51b90-6cd9-4975-8d30-7af980ab3fcc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding dimesion is : (300,)\n",
            "\n",
            "Embedding vector of 'king' is \n",
            "\n",
            " [ 1.25976562e-01  2.97851562e-02  8.60595703e-03  1.39648438e-01\n",
            " -2.56347656e-02 -3.61328125e-02  1.11816406e-01 -1.98242188e-01\n",
            "  5.12695312e-02  3.63281250e-01 -2.42187500e-01 -3.02734375e-01\n",
            " -1.77734375e-01 -2.49023438e-02 -1.67968750e-01 -1.69921875e-01\n",
            "  3.46679688e-02  5.21850586e-03  4.63867188e-02  1.28906250e-01\n",
            "  1.36718750e-01  1.12792969e-01  5.95703125e-02  1.36718750e-01\n",
            "  1.01074219e-01 -1.76757812e-01 -2.51953125e-01  5.98144531e-02\n",
            "  3.41796875e-01 -3.11279297e-02  1.04492188e-01  6.17675781e-02\n",
            "  1.24511719e-01  4.00390625e-01 -3.22265625e-01  8.39843750e-02\n",
            "  3.90625000e-02  5.85937500e-03  7.03125000e-02  1.72851562e-01\n",
            "  1.38671875e-01 -2.31445312e-01  2.83203125e-01  1.42578125e-01\n",
            "  3.41796875e-01 -2.39257812e-02 -1.09863281e-01  3.32031250e-02\n",
            " -5.46875000e-02  1.53198242e-02 -1.62109375e-01  1.58203125e-01\n",
            " -2.59765625e-01  2.01416016e-02 -1.63085938e-01  1.35803223e-03\n",
            " -1.44531250e-01 -5.68847656e-02  4.29687500e-02 -2.46582031e-02\n",
            "  1.85546875e-01  4.47265625e-01  9.58251953e-03  1.31835938e-01\n",
            "  9.86328125e-02 -1.85546875e-01 -1.00097656e-01 -1.33789062e-01\n",
            " -1.25000000e-01  2.83203125e-01  1.23046875e-01  5.32226562e-02\n",
            " -1.77734375e-01  8.59375000e-02 -2.18505859e-02  2.05078125e-02\n",
            " -1.39648438e-01  2.51464844e-02  1.38671875e-01 -1.05468750e-01\n",
            "  1.38671875e-01  8.88671875e-02 -7.51953125e-02 -2.13623047e-02\n",
            "  1.72851562e-01  4.63867188e-02 -2.65625000e-01  8.91113281e-03\n",
            "  1.49414062e-01  3.78417969e-02  2.38281250e-01 -1.24511719e-01\n",
            " -2.17773438e-01 -1.81640625e-01  2.97851562e-02  5.71289062e-02\n",
            " -2.89306641e-02  1.24511719e-02  9.66796875e-02 -2.31445312e-01\n",
            "  5.81054688e-02  6.68945312e-02  7.08007812e-02 -3.08593750e-01\n",
            " -2.14843750e-01  1.45507812e-01 -4.27734375e-01 -9.39941406e-03\n",
            "  1.54296875e-01 -7.66601562e-02  2.89062500e-01  2.77343750e-01\n",
            " -4.86373901e-04 -1.36718750e-01  3.24218750e-01 -2.46093750e-01\n",
            " -3.03649902e-03 -2.11914062e-01  1.25000000e-01  2.69531250e-01\n",
            "  2.04101562e-01  8.25195312e-02 -2.01171875e-01 -1.60156250e-01\n",
            " -3.78417969e-02 -1.20117188e-01  1.15234375e-01 -4.10156250e-02\n",
            " -3.95507812e-02 -8.98437500e-02  6.34765625e-03  2.03125000e-01\n",
            "  1.86523438e-01  2.73437500e-01  6.29882812e-02  1.41601562e-01\n",
            " -9.81445312e-02  1.38671875e-01  1.82617188e-01  1.73828125e-01\n",
            "  1.73828125e-01 -2.37304688e-01  1.78710938e-01  6.34765625e-02\n",
            "  2.36328125e-01 -2.08984375e-01  8.74023438e-02 -1.66015625e-01\n",
            " -7.91015625e-02  2.43164062e-01 -8.88671875e-02  1.26953125e-01\n",
            " -2.16796875e-01 -1.73828125e-01 -3.59375000e-01 -8.25195312e-02\n",
            " -6.49414062e-02  5.07812500e-02  1.35742188e-01 -7.47070312e-02\n",
            " -1.64062500e-01  1.15356445e-02  4.45312500e-01 -2.15820312e-01\n",
            " -1.11328125e-01 -1.92382812e-01  1.70898438e-01 -1.25000000e-01\n",
            "  2.65502930e-03  1.92382812e-01 -1.74804688e-01  1.39648438e-01\n",
            "  2.92968750e-01  1.13281250e-01  5.95703125e-02 -6.39648438e-02\n",
            "  9.96093750e-02 -2.72216797e-02  1.96533203e-02  4.27246094e-02\n",
            " -2.46093750e-01  6.39648438e-02 -2.25585938e-01 -1.68945312e-01\n",
            "  2.89916992e-03  8.20312500e-02  3.41796875e-01  4.32128906e-02\n",
            "  1.32812500e-01  1.42578125e-01  7.61718750e-02  5.98144531e-02\n",
            " -1.19140625e-01  2.74658203e-03 -6.29882812e-02 -2.72216797e-02\n",
            " -4.82177734e-03 -8.20312500e-02 -2.49023438e-02 -4.00390625e-01\n",
            " -1.06933594e-01  4.24804688e-02  7.76367188e-02 -1.16699219e-01\n",
            "  7.37304688e-02 -9.22851562e-02  1.07910156e-01  1.58203125e-01\n",
            "  4.24804688e-02  1.26953125e-01  3.61328125e-02  2.67578125e-01\n",
            " -1.01074219e-01 -3.02734375e-01 -5.76171875e-02  5.05371094e-02\n",
            "  5.26428223e-04 -2.07031250e-01 -1.38671875e-01 -8.97216797e-03\n",
            " -2.78320312e-02 -1.41601562e-01  2.07031250e-01 -1.58203125e-01\n",
            "  1.27929688e-01  1.49414062e-01 -2.24609375e-02 -8.44726562e-02\n",
            "  1.22558594e-01  2.15820312e-01 -2.13867188e-01 -3.12500000e-01\n",
            " -3.73046875e-01  4.08935547e-03  1.07421875e-01  1.06933594e-01\n",
            "  7.32421875e-02  8.97216797e-03 -3.88183594e-02 -1.29882812e-01\n",
            "  1.49414062e-01 -2.14843750e-01 -1.83868408e-03  9.91210938e-02\n",
            "  1.57226562e-01 -1.14257812e-01 -2.05078125e-01  9.91210938e-02\n",
            "  3.69140625e-01 -1.97265625e-01  3.54003906e-02  1.09375000e-01\n",
            "  1.31835938e-01  1.66992188e-01  2.35351562e-01  1.04980469e-01\n",
            " -4.96093750e-01 -1.64062500e-01 -1.56250000e-01 -5.22460938e-02\n",
            "  1.03027344e-01  2.43164062e-01 -1.88476562e-01  5.07812500e-02\n",
            " -9.37500000e-02 -6.68945312e-02  2.27050781e-02  7.61718750e-02\n",
            "  2.89062500e-01  3.10546875e-01 -5.37109375e-02  2.28515625e-01\n",
            "  2.51464844e-02  6.78710938e-02 -1.21093750e-01 -2.15820312e-01\n",
            " -2.73437500e-01 -3.07617188e-02 -3.37890625e-01  1.53320312e-01\n",
            "  2.33398438e-01 -2.08007812e-01  3.73046875e-01  8.20312500e-02\n",
            "  2.51953125e-01 -7.61718750e-02 -4.66308594e-02 -2.23388672e-02\n",
            "  2.99072266e-02 -5.93261719e-02 -4.66918945e-03 -2.44140625e-01\n",
            " -2.09960938e-01 -2.87109375e-01 -4.54101562e-02 -1.77734375e-01\n",
            " -2.79296875e-01 -8.59375000e-02  9.13085938e-02  2.51953125e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unk = 'cameroon'\n",
        "\n",
        "try:\n",
        "    vec_unk = wv[unk]\n",
        "except KeyError:\n",
        "    print(f\"The word #{unk} does not appear in this model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzYMjIa1gNp2",
        "outputId": "95a13758-b6f7-4358-df25-58ae16e578ba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The word #cameroon does not appear in this model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서 알 수 있는 word2vec의 단점 : 모르는 단어에서는 Keyerorr가 발생한다."
      ],
      "metadata": {
        "id": "Xo4I0H39gP2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = [\n",
        "    ('car', 'minivan'),   \n",
        "    ('car', 'bicycle'),  \n",
        "    ('car', 'airplane'),\n",
        "    ('car', 'cereal'),    \n",
        "    ('car', 'democracy')\n",
        "]\n",
        "\n",
        "for w1, w2 in pairs:\n",
        "    print(f'{w1} ======= {w2}\\t  {wv.similarity(w1, w2):.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzJf0eV9gZOo",
        "outputId": "006d7cf9-572e-45a3-95e9-2b7b4b7b6662"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "car ======= minivan\t  0.69\n",
            "car ======= bicycle\t  0.54\n",
            "car ======= airplane\t  0.42\n",
            "car ======= cereal\t  0.14\n",
            "car ======= democracy\t  0.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# korea와 japan의 유사도는?\n",
        "wv.similarity('korea', 'japan')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wWNuvF0h4Vg",
        "outputId": "bd70c7a5-a44b-4900-8384-a1cb24479275"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5648359"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (word, similarity) in enumerate(wv.most_similar(positive=['car', 'minivan'], topn=5)):\n",
        "    print(f\"Top {i+1} : {word}, {similarity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdjrofyNh06k",
        "outputId": "6468a264-bfa9-4cfa-faab-74a5ea246fae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 1 : SUV, 0.8532192707061768\n",
            "Top 2 : vehicle, 0.8175783753395081\n",
            "Top 3 : pickup_truck, 0.7763688564300537\n",
            "Top 4 : Jeep, 0.7567334175109863\n",
            "Top 5 : Ford_Explorer, 0.7565720081329346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wv.most_similar(positive=['canada', 'usa'], topn=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XMlZCZQiIPM",
        "outputId": "35239d2b-ce80-430e-9056-b031067f5a46"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('australia', 0.7461850643157959),\n",
              " ('uk', 0.7346195578575134),\n",
              " ('india', 0.7198905944824219),\n",
              " ('canadian', 0.713864803314209),\n",
              " ('mexico', 0.6899615526199341)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wv.doesnt_match(['fire', 'water', 'land', 'sea', 'air', 'car']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKn5JO51iSZg",
        "outputId": "8ae7ceac-3b6d-4d9d-8e1a-87a38534e493"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "car\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fast text (word2vec방식+철자 단위 임베딩) : unknown단어에 대해서도 처리 가능!   \n",
        "character n-gram    \n",
        "접두사 접미사를 인식할 수 있도록 단어 앞뒤로 <>를 붙여줌    \n",
        "접두사/접미사란? https://post.naver.com/viewer/postView.nhn?volumeNo=23305226&memberNo=46639488   \n"
      ],
      "metadata": {
        "id": "9t3vtusbj5Qb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3-6 gram을 구해준다.    \n",
        "\n",
        "예로 eating에 대한 5-gram을 구한다면   \n",
        "<eat, eatin, ating, ting>   \n",
        "eating에 대한 6-gram을 구한다면   \n",
        "<eatin, eating, ating>   \n",
        "\n",
        "이렇게 구해진 n-gram들에 대해 모두 임베딩 벡터를 구하게 된다.   \n",
        "eating이라는 단어가 말뭉치 내에 있다면?   \n",
        "-> skip-gram으로부터 학습한 임베딩 벡터에 위에서 얻은 character level의 n-gram 벡터를 더해줌    \n",
        "eating이라는 단어가 말뭉치 내에 없다면?    \n",
        "-> 더할게 없으므로 그냥 character level의 n-gram 벡터만으로 구성\n"
      ],
      "metadata": {
        "id": "Vvqqauz7l2Q4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "gensim을 이용한 fasttext 실습"
      ],
      "metadata": {
        "id": "ZEs30_Mcr4hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint as print\n",
        "from gensim.models.fasttext import FastText\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "# Set file names for train and test data\n",
        "corpus_file = datapath('lee_background.cor')\n",
        "\n",
        "model = FastText(vector_size=100)\n",
        "\n",
        "# build the vocabulary\n",
        "model.build_vocab(corpus_file=corpus_file)\n",
        "\n",
        "# train the model\n",
        "model.train(\n",
        "    corpus_file=corpus_file, epochs=model.epochs,\n",
        "    total_examples=model.corpus_count, total_words=model.corpus_total_words,\n",
        ")\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbBoW8JJkyqz",
        "outputId": "1b2ea54d-c736-4dde-dba4-f1483ae120b9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<gensim.models.fasttext.FastText object at 0x7f3600c12ad0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft = model.wv\n",
        "print(ft)\n",
        "\n",
        "#\n",
        "# FastText models support vector lookups for out-of-vocabulary words by summing up character ngrams belonging to the word.\n",
        "#\n",
        "print(f\"night => {'night' in ft.key_to_index}\")\n",
        "print(f\"nights => {'nights' in ft.key_to_index}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Hwfk-JCkU6E",
        "outputId": "38857dd8-1d84-468c-b133-918c3310caf3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<gensim.models.fasttext.FastTextKeyedVectors object at 0x7f3600c3f490>\n",
            "'night => True'\n",
            "'nights => False'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ft['night'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I91jm8QLjrFk",
        "outputId": "3a452e08-0d9d-420e-f276-97aa9fbdc997"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array([-0.14971754,  0.10469075, -0.2373039 , -0.09053431,  0.05325599,\n",
            "        0.34626472,  0.36635157,  0.548381  ,  0.1803899 , -0.26492742,\n",
            "        0.01465592, -0.13937871, -0.2697806 ,  0.58564323, -0.3616493 ,\n",
            "       -0.53942084,  0.14611562, -0.22175258, -0.44538587, -0.5065588 ,\n",
            "       -0.46730646,  0.00141708, -0.5256473 , -0.13251278, -0.17952877,\n",
            "       -0.26496705, -0.6093761 , -0.09378491, -0.23071146,  0.2217205 ,\n",
            "       -0.29421577,  0.31488836,  0.8367941 , -0.21737069,  0.2080949 ,\n",
            "        0.2856565 ,  0.40098736, -0.05101724, -0.3611254 , -0.29858935,\n",
            "        0.49584773, -0.4540443 ,  0.0887953 , -0.3525736 , -0.54950774,\n",
            "       -0.36074337, -0.02939658,  0.17322785,  0.28879777, -0.04646828,\n",
            "        0.3725494 , -0.48789063,  0.25854692, -0.42032135, -0.20470756,\n",
            "       -0.23750193, -0.17839885, -0.13964088,  0.01531312, -0.32822078,\n",
            "       -0.3517667 , -0.46159613, -0.26555282,  0.3763934 , -0.06675389,\n",
            "        0.6932174 ,  0.05130324, -0.00541648,  0.3877058 ,  0.31924713,\n",
            "       -0.22258274,  0.4392814 ,  0.5669483 , -0.6602756 ,  0.3082263 ,\n",
            "       -0.0803635 ,  0.26536897, -0.08567641,  0.10834669,  0.36553562,\n",
            "        0.1386676 , -0.46089637, -0.7745144 , -0.15741724, -0.11387   ,\n",
            "       -0.7518231 ,  0.46800926,  0.22565131, -0.05131103, -0.322215  ,\n",
            "       -0.06836051,  0.37884778, -0.17161575,  0.0767361 , -0.2577835 ,\n",
            "        0.578394  , -0.20126705, -0.24019746, -0.03118589, -0.28954488],\n",
            "      dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ft['nights'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xibhERXbsGd_",
        "outputId": "5cae7fd3-cf80-4afa-da70-7dd6b2af1657"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array([-1.30850106e-01,  9.19173062e-02, -2.06366822e-01, -7.85146654e-02,\n",
            "        4.50116098e-02,  2.99752146e-01,  3.19793493e-01,  4.78594929e-01,\n",
            "        1.57320321e-01, -2.32010663e-01,  1.44910328e-02, -1.19680725e-01,\n",
            "       -2.35639155e-01,  5.07061720e-01, -3.15763623e-01, -4.69562471e-01,\n",
            "        1.26338586e-01, -1.92275405e-01, -3.85837704e-01, -4.41108733e-01,\n",
            "       -4.03383344e-01,  1.37968644e-04, -4.56867099e-01, -1.16648249e-01,\n",
            "       -1.54737413e-01, -2.28915036e-01, -5.28422296e-01, -7.93029964e-02,\n",
            "       -2.00298399e-01,  1.94283172e-01, -2.53817827e-01,  2.73211360e-01,\n",
            "        7.25660980e-01, -1.88531622e-01,  1.80992708e-01,  2.47760609e-01,\n",
            "        3.49971533e-01, -4.43399139e-02, -3.14136028e-01, -2.60123044e-01,\n",
            "        4.30136621e-01, -3.93740922e-01,  7.66546801e-02, -3.05950940e-01,\n",
            "       -4.78427202e-01, -3.12294811e-01, -2.26179175e-02,  1.51171789e-01,\n",
            "        2.52420187e-01, -3.93090770e-02,  3.25372249e-01, -4.24272776e-01,\n",
            "        2.25363389e-01, -3.65249425e-01, -1.77483842e-01, -2.05188930e-01,\n",
            "       -1.56977952e-01, -1.19598046e-01,  1.46339433e-02, -2.82603443e-01,\n",
            "       -3.04692149e-01, -4.01528299e-01, -2.30425701e-01,  3.26642275e-01,\n",
            "       -5.74335866e-02,  6.03572488e-01,  4.46585603e-02, -7.35199777e-03,\n",
            "        3.36724460e-01,  2.78639793e-01, -1.93983883e-01,  3.79892498e-01,\n",
            "        4.93903697e-01, -5.73757827e-01,  2.69393027e-01, -6.88406900e-02,\n",
            "        2.30050623e-01, -7.52627626e-02,  9.39388946e-02,  3.17777991e-01,\n",
            "        1.21028252e-01, -4.01022673e-01, -6.72600806e-01, -1.37875885e-01,\n",
            "       -9.79529098e-02, -6.54652596e-01,  4.06735361e-01,  1.96325392e-01,\n",
            "       -4.25435267e-02, -2.80704349e-01, -5.93633652e-02,  3.28074485e-01,\n",
            "       -1.49676740e-01,  6.73591122e-02, -2.24514216e-01,  5.02873123e-01,\n",
            "       -1.76300079e-01, -2.05149993e-01, -2.67826896e-02, -2.52502263e-01],\n",
            "      dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ft.similarity(\"night\", \"nights\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_Q8ly9nsL36",
        "outputId": "8a4d3dd4-8b93-4566-c896-57e771b8890b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.99999183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ft.most_similar(\"nights\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xIGZf0GsN2f",
        "outputId": "2c5a3cfd-1c27-41b2-b9d4-872946f19f5f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('night', 0.9999918341636658),\n",
            " ('rights', 0.9999879598617554),\n",
            " ('flights', 0.9999877214431763),\n",
            " ('overnight', 0.999987006187439),\n",
            " ('fighting', 0.99998539686203),\n",
            " ('fighters', 0.9999852180480957),\n",
            " ('entered', 0.9999850988388062),\n",
            " ('fight', 0.9999849796295166),\n",
            " ('fighter', 0.9999847412109375),\n",
            " ('eight', 0.9999844431877136)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "비슷하게 생긴 (비슷한 chracter n-gram이 포함된) 단어가 많이 속해있음"
      ],
      "metadata": {
        "id": "qo0AyePtsRJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ft.doesnt_match(\"night noon fight morning\".split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxXKaEdfsO5n",
        "outputId": "7b689663-3ae5-4091-fd3b-4927692d6318"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'noon'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fasttext 임베딩 벡터는 단어의 의미보다는 단어의 모양에 더 신경쓰는 것 같기도..."
      ],
      "metadata": {
        "id": "ExfqWF6dsrVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ft.doesnt_match(\"bye hello hi mellon\".split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4QkYh-SshJt",
        "outputId": "999c885b-b452-4ab4-b0e0-00926d4e0780"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'bye'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 아까의 word2vec다시 한번 보자\n",
        "print(wv.doesnt_match(['bye', 'hello', 'hi', 'mellon']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY9FwFrntVlQ",
        "outputId": "df4e8ce9-167a-4f13-cb2d-c1990e292682"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'mellon'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그냥 word2vec은 잘 구별하는 것을 알 수 있다. (의미 중심으로 임베딩이 되어서 그런 듯)"
      ],
      "metadata": {
        "id": "2Tp8ax-_tnUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.datasets import imdb"
      ],
      "metadata": {
        "id": "Y60LVcbHulUX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42) # 항상 같은 결과를 도출하기 위해 전역 random seed 설정 "
      ],
      "metadata": {
        "id": "yjdyOG-HtmrR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=20000)\n",
        "# imdb의 return은 (X_train, y_train), (X_test, y_test)형식이라고 한다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8tQRVTjtlei",
        "outputId": "e9f31fac-30d8-4ae0-ac37-a8e138391c32"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train set shape : {X_train.shape}\")\n",
        "print(f\"Test set shape : {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWkNWK05wixT",
        "outputId": "a1bb2061-86de-4ba4-8d83-694b7cb315b4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Train set shape : (25000,)'\n",
            "'Test set shape : (25000,)'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0] # 이게 뭘 한거지............! 인덱스라고 한다. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yed1zbqWxPdk",
        "outputId": "f453374d-f0f3-45b9-960f-1463f33edcc7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 19193,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 10311,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 12118,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    \"\"\"\n",
        "    word_index를 받아 text를 sequence 형태로 반환하는 함수입니다.\n",
        "    \"\"\"\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-LVW9jsxP5P",
        "outputId": "ebbe847a-c08e-41e3-e607-2f0025970ef0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode_review(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "cgpkgeBvxdxR",
        "outputId": "f6affd41-7aaa-4430-c247-989880689f38"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [decode_review(idx) for idx in X_train]\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)"
      ],
      "metadata": {
        "id": "0dZIYlegzLzJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCyvJnkq0Ydx",
        "outputId": "83d4fd2f-cac5-406b-fbaf-2995f712cf91"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_encoded = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "#\n",
        "max_len = max(len(sent) for sent in X_encoded)\n",
        "print(max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3HDMbAr0aJd",
        "outputId": "d9a8e54d-677d-4e16-a960-05537d6456c1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Mean length of train set: {np.mean([len(sent) for sent in X_train], dtype=int)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbDZSjYI0o-1",
        "outputId": "4e96b08c-8e2a-46a5-9176-f5e0f61b3480"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Mean length of train set: 238'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=pad_sequences(X_encoded, maxlen=400, padding='post') # post는 뒤에 0을 붙여준다는 뜻\n",
        "y_train=np.array(y_train)"
      ],
      "metadata": {
        "id": "kTcPApMc0tpu"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "\n",
        "print(np.shape(embedding_matrix)) # 가중치 행렬 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk2_Bz6k4Ih9",
        "outputId": "d902346b-0c14-4a14-a3ed-25cf6fec2038"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19999, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vector(word):\n",
        "    \"\"\"\n",
        "    해당 word가 word2vec에 있는 단어일 경우 임베딩 벡터를 반환\n",
        "    \"\"\"\n",
        "    if word in wv:\n",
        "        return wv[word]\n",
        "    else:\n",
        "        return None\n",
        " \n",
        "for word, i in tokenizer.word_index.items():\n",
        "    temp = get_vector(word)\n",
        "    if temp is not None:\n",
        "        embedding_matrix[i] = temp"
      ],
      "metadata": {
        "id": "UF2g8c6-4Srv"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten"
      ],
      "metadata": {
        "id": "lCmL4YXK4UMv"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=400, trainable=False)) # trainable=False 해당 layer는 학습하지 않고 동결한다.(학습 문장에 대한 임베딩 벡터라서 딱히 학습에 포함시켜줄 필요가 없는 걸까?)\n",
        "model.add(GlobalAveragePooling1D()) # 입력되는 단어 벡터의 평균을 구하는 함수입니다.\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "OcxMXY1B6p11"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "임베딩 레이어는 어떻게 작동하는가?   \n",
        "https://androidkt.com/how-embedding-layer-work-in-keras/"
      ],
      "metadata": {
        "id": "i4FT1iKf_Ql1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgqaVRvo_z1o",
        "outputId": "1c10c856-bb9b-4f0e-a7d3-6c67b92a2eef"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTQXErYf6sO9",
        "outputId": "61533b48-8f82-493e-b2e2-85c38d619d62"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 10s 30ms/step - loss: 0.6924 - acc: 0.5242 - val_loss: 0.6908 - val_acc: 0.5852\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 10s 30ms/step - loss: 0.6902 - acc: 0.5735 - val_loss: 0.6884 - val_acc: 0.5944\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.6881 - acc: 0.5885 - val_loss: 0.6861 - val_acc: 0.5974\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 9s 27ms/step - loss: 0.6862 - acc: 0.5910 - val_loss: 0.6838 - val_acc: 0.5904\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.6846 - acc: 0.5944 - val_loss: 0.6825 - val_acc: 0.6024\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 9s 27ms/step - loss: 0.6828 - acc: 0.5952 - val_loss: 0.6801 - val_acc: 0.5934\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.6813 - acc: 0.6016 - val_loss: 0.6788 - val_acc: 0.6104\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 9s 27ms/step - loss: 0.6798 - acc: 0.6036 - val_loss: 0.6775 - val_acc: 0.6100\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.6785 - acc: 0.6043 - val_loss: 0.6756 - val_acc: 0.6136\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 10s 32ms/step - loss: 0.6773 - acc: 0.6079 - val_loss: 0.6743 - val_acc: 0.6176\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6759 - acc: 0.6095 - val_loss: 0.6730 - val_acc: 0.6154\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 9s 27ms/step - loss: 0.6748 - acc: 0.6109 - val_loss: 0.6717 - val_acc: 0.6178\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 9s 27ms/step - loss: 0.6736 - acc: 0.6102 - val_loss: 0.6713 - val_acc: 0.6142\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.6725 - acc: 0.6136 - val_loss: 0.6691 - val_acc: 0.6224\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 10s 32ms/step - loss: 0.6713 - acc: 0.6138 - val_loss: 0.6680 - val_acc: 0.6220\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 10s 33ms/step - loss: 0.6704 - acc: 0.6152 - val_loss: 0.6674 - val_acc: 0.6230\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 11s 36ms/step - loss: 0.6694 - acc: 0.6188 - val_loss: 0.6670 - val_acc: 0.6208\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.6684 - acc: 0.6211 - val_loss: 0.6650 - val_acc: 0.6286\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 10s 33ms/step - loss: 0.6675 - acc: 0.6215 - val_loss: 0.6642 - val_acc: 0.6272\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 11s 36ms/step - loss: 0.6666 - acc: 0.6237 - val_loss: 0.6633 - val_acc: 0.6270\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3585c4c1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "밑에서부터는 이것저것 테스트"
      ],
      "metadata": {
        "id": "YhkgZmF3Lj-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtqlQwByKQnu",
        "outputId": "7bbcdd7b-6278-4b54-bcb8-1a4e0d693040"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   30,   590,   201, ...,     0,     0,     0],\n",
              "       [   30,    12,    20, ...,     0,     0,     0],\n",
              "       [10117,   545,     3, ...,     7,    56,   977],\n",
              "       ...,\n",
              "       [   30,    11,  1407, ...,     0,     0,     0],\n",
              "       [   30,     9,   118, ...,     0,     0,     0],\n",
              "       [   30,     4,    51, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = [decode_review(idx) for idx in X_test]\n",
        "\n",
        "X_test_encoded = tokenizer.texts_to_sequences(test_sentences)"
      ],
      "metadata": {
        "id": "sSygpG27JA5J"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test=pad_sequences(X_test_encoded, maxlen=400, padding='post')\n",
        "y_test=np.array(y_test)"
      ],
      "metadata": {
        "id": "pw0P2PnzJUyp"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu9XZ1_-JeL5",
        "outputId": "5e9e0842-e70f-494e-8d9c-9281be794fc9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 4s 5ms/step - loss: 0.6679 - acc: 0.6102\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6679435968399048, 0.6101999878883362]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = ['this is just love i like it']"
      ],
      "metadata": {
        "id": "8NJs0kCrJfIL"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sen = tokenizer.texts_to_sequences(sentence)"
      ],
      "metadata": {
        "id": "0jn7-PzZJ9Fk"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = pad_sequences(tokenized_sen, maxlen=400, padding='post')"
      ],
      "metadata": {
        "id": "oQwXZd3GKEki"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH1ilQ63K6YH",
        "outputId": "0618c741-9d79-4ca8-b2e8-189243ffc14c"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.52203685],\n",
              "       [0.52172965],\n",
              "       [0.5198791 ],\n",
              "       [0.52078205],\n",
              "       [0.52094084],\n",
              "       [0.5198791 ],\n",
              "       [0.52078205],\n",
              "       [0.52094084],\n",
              "       [0.5205391 ],\n",
              "       [0.5216519 ],\n",
              "       [0.52078205],\n",
              "       [0.52203685],\n",
              "       [0.52094084],\n",
              "       [0.52282614],\n",
              "       [0.5220456 ],\n",
              "       [0.5208798 ],\n",
              "       [0.52230227],\n",
              "       [0.52094084],\n",
              "       [0.5198791 ],\n",
              "       [0.52094084],\n",
              "       [0.52282614],\n",
              "       [0.5198791 ],\n",
              "       [0.52388406],\n",
              "       [0.52230227],\n",
              "       [0.52094084],\n",
              "       [0.5198791 ],\n",
              "       [0.52203685]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "embedding layer에 대한 설명   \n",
        "https://ebbnflow.tistory.com/154   \n",
        "NLP task 를 수행하기 전, 단어를 벡터로 만드는 임베딩 작업 !!!   \n",
        "케라스를 이용하는 법 두가지    \n",
        "1. 캐라스 내장 함수 Embedding()\n",
        "2. pre trained word embedding 가져오서 embedding layer에 주입\n"
      ],
      "metadata": {
        "id": "eixWLkT2DZCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "[note]\n",
        "이 코드는 위의 티스토리 페이지에서 가져온 코드(이해를 돕기 위함)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import gensim\n",
        " \n",
        "# 구글의 사전 훈련된 Word2vec 모델을 로드합니다.\n",
        "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
        " \n",
        "print(word2vec_model.vectors.shape) # (3000000, 300)\n",
        " \n",
        "embedding_matrix = np.zeros((vocab_size, 300)) => 이렇게 메트릭스를 만들어서 넣어준다?\n",
        "# 단어 집합 크기의 행과 300개의 열을 가지는 행렬 생성. 값은 전부 0으로 채워진다.\n",
        "print(np.shape(embedding_matrix)) # (16, 300)\n",
        " \n",
        "def get_vector(word):\n",
        "    if word in word2vec_model:\n",
        "        return word2vec_model[word]\n",
        "    else:\n",
        "        return None\n",
        " \n",
        "for word, i in t.word_index.items(): # 훈련 데이터의 단어 집합에서 단어와 정수 인덱스를 1개씩 꺼내온다.\n",
        "    temp = get_vector(word) # 단어(key) 해당되는 임베딩 벡터의 300개의 값(value)를 임시 변수에 저장\n",
        "    if temp is not None: # 만약 None이 아니라면 임베딩 벡터의 값을 리턴받은 것이므로\n",
        "        embedding_matrix[i] = temp # 해당 단어 위치의 행에 벡터의 값을 저장한다.\n",
        " \n",
        " \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        " \n",
        "model = Sequential()\n",
        "e = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_len, trainable=False)\n",
        "model.add(e)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.fit(X_train, y_train, epochs=100, verbose=2)\n",
        "\n",
        "\n",
        "출처: https://ebbnflow.tistory.com/154 [Dev Log : 삶은 확률의 구름]\n",
        "'''"
      ],
      "metadata": {
        "id": "DvuLpoq8EWxe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}